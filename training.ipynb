{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "soSPiBszSQPf"
      },
      "outputs": [],
      "source": [
        "# importing the required libraries\n",
        "import xml.etree.ElementTree as ET\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import gensim.downloader as api\n",
        "from tensorflow.keras.layers import Embedding\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "tf.random.set_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezsTKigsSasF",
        "outputId": "a3b82f1e-7ed2-4c48-a907-ebcce2f55530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1r8SeRlZgWXd5UDuWBUMZ4_4A9bb_6SjY\n",
            "From (redirected): https://drive.google.com/uc?id=1r8SeRlZgWXd5UDuWBUMZ4_4A9bb_6SjY&confirm=t&uuid=06ef58af-29b9-48ec-a7e6-9eb77204dfce\n",
            "To: /content/ABSA16_Restaurants_Train_SB1_v2.xml\n",
            "100% 723k/723k [00:00<00:00, 16.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UmEt8uQuTF6aa2nwTywqFOLRPHp6kkVv\n",
            "To: /content/EN_LAPT_SB1_TEST_.xml.gold\n",
            "100% 272k/272k [00:00<00:00, 62.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uw1xQ-ryaWtZeDRzvCAIlKJlGFadUdyL\n",
            "To: /content/EN_REST_SB1_TEST.xml.gold\n",
            "100% 266k/266k [00:00<00:00, 25.4MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Zg7-x5iHtFelx_sKQJfsgrU_YHtKXXCr\n",
            "From (redirected): https://drive.google.com/uc?id=1Zg7-x5iHtFelx_sKQJfsgrU_YHtKXXCr&confirm=t&uuid=4089e18e-c442-458c-ab02-9ad95c6fa1cd\n",
            "To: /content/Laptop_Train_v2.xml\n",
            "100% 687k/687k [00:00<00:00, 77.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TJDZsa5IOqxuQryhhFQovN72i-1rBLPZ\n",
            "To: /content/restaurants-train.json\n",
            "100% 927k/927k [00:00<00:00, 12.5MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1uXQSKet_KYkQVYyTWmjnYqFebadRtikn\n",
            "From (redirected): https://drive.google.com/uc?id=1uXQSKet_KYkQVYyTWmjnYqFebadRtikn&confirm=t&uuid=aa400553-6a16-496d-8d61-5379ba2cd58d\n",
            "To: /content/restaurants-train.xml\n",
            "100% 1.11M/1.11M [00:00<00:00, 30.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# downloading the dataset\n",
        "!gdown 1r8SeRlZgWXd5UDuWBUMZ4_4A9bb_6SjY --fuzzy\n",
        "!gdown 1UmEt8uQuTF6aa2nwTywqFOLRPHp6kkVv --fuzzy\n",
        "!gdown 1uw1xQ-ryaWtZeDRzvCAIlKJlGFadUdyL --fuzzy\n",
        "!gdown 1Zg7-x5iHtFelx_sKQJfsgrU_YHtKXXCr --fuzzy\n",
        "!gdown 1TJDZsa5IOqxuQryhhFQovN72i-1rBLPZ --fuzzy\n",
        "!gdown 1uXQSKet_KYkQVYyTWmjnYqFebadRtikn --fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-ETphRiShRn"
      },
      "outputs": [],
      "source": [
        "# defining labels\n",
        "polar_idx={'positive':0,'negative':1,'neutral':2}\n",
        "idx_polar={v:k for k,v in polar_idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBxChtBiTG1F"
      },
      "outputs": [],
      "source": [
        "# extract xml file into dictionary form.\n",
        "def parse_xml_2014(fn):\n",
        "\n",
        "        root = ET.parse(fn).getroot()\n",
        "        corpus = []\n",
        "        for review in root.iter(\"Review\"):\n",
        "            for sent in review.iter(\"sentence\"):\n",
        "                target2polarity = {}\n",
        "                forbid = []\n",
        "                for ix, opin in enumerate(sent.iter('Opinion')):\n",
        "                    if opin.attrib['polarity'] in polar_idx:\n",
        "                        if opin.attrib['target'] in target2polarity and target2polarity[opin.attrib['target']] != opin.attrib['polarity']:\n",
        "                            forbid.append(opin.attrib['target'])\n",
        "                        target2polarity[opin.attrib['target']] = opin.attrib['polarity']\n",
        "\n",
        "                for ix, opin in enumerate(sent.iter('Opinion')):\n",
        "                    if opin.attrib['target'] not in forbid:\n",
        "                        corpus.append({\"id\": sent.attrib['id']+\"_\"+str(ix),\n",
        "                                        \"sentence\": sent.find('text').text,\n",
        "                                        \"term\": opin.attrib['target'],\n",
        "                                        \"polarity\": opin.attrib['polarity']})\n",
        "\n",
        "        return corpus\n",
        "\n",
        "\n",
        "# extract xml file into dictionary form.\n",
        "def parse_xml_2016(fn):\n",
        "  import json\n",
        "  f = open(fn)\n",
        "  data = json.load(f)\n",
        "  corpus = []\n",
        "  for i in range(len(data)):\n",
        "    txt = data[i]['text']\n",
        "    tmp = data[i]['opinions']['aspect_term']\n",
        "    for j in  range(len(tmp)):\n",
        "      labl = tmp[j]['polarity']\n",
        "      trm = tmp[j]['term']\n",
        "      corpus.append({'sentence':txt, 'term': trm, 'polarity': labl})\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtpUXaZSTU6A"
      },
      "outputs": [],
      "source": [
        "#V1 datset\n",
        "restaurant_v1 = pd.DataFrame.from_dict(parse_xml_2014('ABSA16_Restaurants_Train_SB1_v2.xml'))\n",
        "\n",
        "#V2 dataset\n",
        "restaurant_v2 = pd.DataFrame.from_dict(parse_xml_2014('EN_REST_SB1_TEST.xml.gold'))\n",
        "\n",
        "# V3 dataset\n",
        "restaurant_v3 = pd.DataFrame.from_dict(parse_xml_2016('restaurants-train.json'))\n",
        "\n",
        "# combining the V1,V2 and V3 into a single dataframe\n",
        "df=pd.concat([restaurant_v1,restaurant_v2,restaurant_v3],axis=0)\n",
        "\n",
        "# dropping the id column\n",
        "df=df.drop(columns=['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BCrmlwlLTh9w",
        "outputId": "a206aca3-65bf-4509-f7f2-8e2558ce94d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               sentence                  term  \\\n",
              "0     Judging from previous posts this used to be a ...                 place   \n",
              "1     We, there were four of us, arrived at noon - t...                 staff   \n",
              "2     They never brought us complimentary noodles, i...                  NULL   \n",
              "3     The food was lousy - too sweet or too salty an...                  food   \n",
              "4     The food was lousy - too sweet or too salty an...              portions   \n",
              "...                                                 ...                   ...   \n",
              "3688  Each table has a pot of boiling water sunken i...  pot of boiling water   \n",
              "3689  Each table has a pot of boiling water sunken i...                 meats   \n",
              "3690  Each table has a pot of boiling water sunken i...            vegetables   \n",
              "3691  Each table has a pot of boiling water sunken i...                  rice   \n",
              "3692  Each table has a pot of boiling water sunken i...         glass noodles   \n",
              "\n",
              "      polarity  \n",
              "0     negative  \n",
              "1     negative  \n",
              "2     negative  \n",
              "3     negative  \n",
              "4     negative  \n",
              "...        ...  \n",
              "3688   neutral  \n",
              "3689   neutral  \n",
              "3690   neutral  \n",
              "3691   neutral  \n",
              "3692   neutral  \n",
              "\n",
              "[6935 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c90085f4-27a8-4cae-9efa-383aad7faf15\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>term</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Judging from previous posts this used to be a ...</td>\n",
              "      <td>place</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>We, there were four of us, arrived at noon - t...</td>\n",
              "      <td>staff</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They never brought us complimentary noodles, i...</td>\n",
              "      <td>NULL</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The food was lousy - too sweet or too salty an...</td>\n",
              "      <td>food</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The food was lousy - too sweet or too salty an...</td>\n",
              "      <td>portions</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3688</th>\n",
              "      <td>Each table has a pot of boiling water sunken i...</td>\n",
              "      <td>pot of boiling water</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3689</th>\n",
              "      <td>Each table has a pot of boiling water sunken i...</td>\n",
              "      <td>meats</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3690</th>\n",
              "      <td>Each table has a pot of boiling water sunken i...</td>\n",
              "      <td>vegetables</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3691</th>\n",
              "      <td>Each table has a pot of boiling water sunken i...</td>\n",
              "      <td>rice</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3692</th>\n",
              "      <td>Each table has a pot of boiling water sunken i...</td>\n",
              "      <td>glass noodles</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6935 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c90085f4-27a8-4cae-9efa-383aad7faf15')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c90085f4-27a8-4cae-9efa-383aad7faf15 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c90085f4-27a8-4cae-9efa-383aad7faf15');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0ce4aac2-4804-48f3-9079-5606210d8d05\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ce4aac2-4804-48f3-9079-5606210d8d05')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0ce4aac2-4804-48f3-9079-5606210d8d05 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_64dba45c-b014-4be2-aee4-6387e04eb05d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_64dba45c-b014-4be2-aee4-6387e04eb05d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6935,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3606,\n        \"samples\": [\n          \"I would definitely go back -- if only for some of those exotic martinis on the blackboard.\",\n          \"Best drumsticks over rice and sour spicy soup in town!\",\n          \"When I walked in, I was taken aback by their incredible wood decor.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"term\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1804,\n        \"samples\": [\n          \"kinds of beer\",\n          \"atmosphere\",\n          \"Slamwich\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"positive\",\n          \"conflict\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsjO7dpKTxRH"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_FBwTBGU2-n",
        "outputId": "cd690981-6778-4b09-b61c-61b660b865c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 6935 entries, 0 to 3692\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   sentence  6935 non-null   object\n",
            " 1   term      6935 non-null   object\n",
            " 2   polarity  6935 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 216.7+ KB\n"
          ]
        }
      ],
      "source": [
        "# basic check\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFMG4M88U7p_",
        "outputId": "0a7238c4-21d1-4065-f01b-70d919c08908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the Dataset is (6935, 3)\n"
          ]
        }
      ],
      "source": [
        "print(f\"The shape of the Dataset is {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eQE3zZMVC1_",
        "outputId": "974071dc-eddc-4458-c8e1-1f74f0773c29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentence    3606\n",
              "term        1804\n",
              "polarity       4\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNDoPB_9VFdS",
        "outputId": "fd6da502-2251-46d7-94e8-0e9094d1668c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'positive', 'neutral', 'conflict'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# checking what kind of polarities do we have\n",
        "df['polarity'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpKmAGhMVrEr",
        "outputId": "30017c24-8bf4-4a99-f387-d6a08e4af6e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    4381\n",
              "negative    1704\n",
              "neutral      759\n",
              "conflict      91\n",
              "Name: polarity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# checking the distribution of polarities\n",
        "df['polarity'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJN4YHz6VQ3v",
        "outputId": "62e3df0a-66c3-470a-a002-e90c317e00f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the Dataframe after removing the rows where the label is conflict  (6844, 3)\n"
          ]
        }
      ],
      "source": [
        "# removing the rows where label is \"conflict\"\n",
        "df=df[df['polarity']!='conflict']\n",
        "\n",
        "print(\"The shape of the Dataframe after removing the rows where the label is conflict \",df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KJHVTF7V5uK",
        "outputId": "c1f81285-3eb2-4893-f5a5-e224e69956da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    4381\n",
              "negative    1704\n",
              "neutral      759\n",
              "Name: polarity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df['polarity'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K2SUT0cY_fV",
        "outputId": "c6819574-7ef6-4c6a-8930-84a643478d08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    0.640123\n",
              "negative    0.248977\n",
              "neutral     0.110900\n",
              "Name: polarity, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df['polarity'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLiBmb_tVmr7"
      },
      "source": [
        "The Data is imbalanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSKD5wgjZWcf",
        "outputId": "3b9f0d3f-a875-4295-ac9b-1fd1e93e8cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 1320 rows where term=NULL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-bd72055641ab>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['term'] = df['term'].apply(lambda x: x if len(x.split(' '))<=2 else 'NULL')\n"
          ]
        }
      ],
      "source": [
        "df['term'] = df['term'].apply(lambda x: x if len(x.split(' '))<=2 else 'NULL')\n",
        "print(f\"We have {sum(df['term']=='NULL')} rows where term=NULL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WZ9rMhVZG6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a910e597-abfe-44de-93a6-f5a19e537895"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the Dataframe after removing the rows is (5524, 3)\n"
          ]
        }
      ],
      "source": [
        "# so removing those rows\n",
        "mask=df['term']!='NULL'\n",
        "df=df[mask]\n",
        "print(f\"The shape of the Dataframe after removing the rows is {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9KMTf_jbx2W"
      },
      "source": [
        "### Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EeRNjgj7b5mD"
      },
      "outputs": [],
      "source": [
        "# defining a function which removes the punctuations from a string\n",
        "import string\n",
        "def clean_text(s):\n",
        "  out = s.translate(str.maketrans('', '', string.punctuation))\n",
        "  return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Pyc2hebcVA2"
      },
      "outputs": [],
      "source": [
        "# encoding the labels\n",
        "df=df.replace({'polarity' : { 'positive' : 2, 'negative' : 0, 'neutral' : 1}})\n",
        "\n",
        "# removing the punctuations in the senteneces\n",
        "df['sentence']=df['sentence'].apply(lambda x: clean_text(x))\n",
        "\n",
        "# converting the text into lowercase\n",
        "df['sentence']=df['sentence'].apply(lambda x: x.lower() )\n",
        "\n",
        "# converting the terms to the lower case\n",
        "df['term']=df['term'].apply(lambda x: x.lower() )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F2nSCWZjdksq",
        "outputId": "a1517fcc-b561-41d0-c293-7a6911f77cd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i tend to judge a sushi restaurant by its sea urchin which was heavenly at sushi rose'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# sanity check\n",
        "import random\n",
        "idx = random.randint(0, 100)\n",
        "df.iloc[idx]['sentence']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['polarity'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG5XtB5vbLej",
        "outputId": "8f1fca7b-64e0-4508-d0d6-723ff40dfc45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    3555\n",
              "0    1302\n",
              "1     667\n",
              "Name: polarity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data is imbalanced"
      ],
      "metadata": {
        "id": "K3og7PuebhqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# doing oversampling since the data is imbalanced\n",
        "def oversample(train_df,max_size=1356):\n",
        "\n",
        "  # iterating through each group\n",
        "  for class_idx,group in train_df.groupby('polarity'):\n",
        "    # checking the if the no of datapoints in the class is less than max_size\n",
        "    if len(group)<max_size:\n",
        "      # sample max_size-len(group) no of points\n",
        "      sampled=group.sample(max_size-len(group), replace=True)\n",
        "      train_df = pd.concat([train_df, sampled], ignore_index=True)\n",
        "\n",
        "  return train_df\n",
        "\n",
        "df=oversample(df,max_size=1356)"
      ],
      "metadata": {
        "id": "FcRsoVqma6Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity check whether the data is balanced\n",
        "df['polarity'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HVK9oGhbQfC",
        "outputId": "ee450ff5-6b38-4ede-fcd4-2897917df0e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    3555\n",
              "0    1356\n",
              "1    1356\n",
              "Name: polarity, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes our data is balanced"
      ],
      "metadata": {
        "id": "OJ0C4IctbZrr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMmCyiJ_fn3h",
        "outputId": "6b0180c6-e22e-4032-ac8b-0cb0e9886dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the training data (3760, 2)\n",
            "The shape of the testing data (1253, 2)\n",
            "The shape of the validation data (1254, 2)\n"
          ]
        }
      ],
      "source": [
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y=df['polarity']\n",
        "x=df.drop(columns=['polarity'])\n",
        "\n",
        "x_train,x_val_test,y_train,y_val_test= train_test_split(x,y,test_size=0.4,random_state=42)\n",
        "x_test,x_val,y_test,y_val=train_test_split(x_val_test,y_val_test,test_size=0.5,random_state=42)\n",
        "\n",
        "print(f\"The shape of the training data {x_train.shape}\")\n",
        "print(f\"The shape of the testing data {x_test.shape}\")\n",
        "print(f\"The shape of the validation data {x_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wv3JAGhnhfMB"
      },
      "outputs": [],
      "source": [
        "# tokenization\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# creating and fitting the tokenizer\n",
        "tokenizer=Tokenizer(lower=True)\n",
        "tokenizer.fit_on_texts(x_train['sentence'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras as ke\n",
        "ke.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W6OLg4YRtFH2",
        "outputId": "579dc5cf-8106-41fc-9dcc-2e5d5a166c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('tokenizer_new.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "w2VsGDC1sV-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL6Bbi5BjHXA",
        "outputId": "9f3ac8c8-d306-45c1-c505-85b275da5546"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'and': 2,\n",
              " 'a': 3,\n",
              " 'is': 4,\n",
              " 'to': 5,\n",
              " 'was': 6,\n",
              " 'food': 7,\n",
              " 'of': 8,\n",
              " 'for': 9,\n",
              " 'i': 10,\n",
              " 'in': 11,\n",
              " 'service': 12,\n",
              " 'great': 13,\n",
              " 'with': 14,\n",
              " 'we': 15,\n",
              " 'but': 16,\n",
              " 'you': 17,\n",
              " 'it': 18,\n",
              " 'are': 19,\n",
              " 'good': 20,\n",
              " 'not': 21,\n",
              " 'that': 22,\n",
              " 'have': 23,\n",
              " 'this': 24,\n",
              " 'place': 25,\n",
              " 'were': 26,\n",
              " 'at': 27,\n",
              " 'had': 28,\n",
              " 'on': 29,\n",
              " 'very': 30,\n",
              " 'they': 31,\n",
              " 'my': 32,\n",
              " 'so': 33,\n",
              " 'be': 34,\n",
              " 'as': 35,\n",
              " 'our': 36,\n",
              " 'an': 37,\n",
              " 'restaurant': 38,\n",
              " 'if': 39,\n",
              " 'wine': 40,\n",
              " 'all': 41,\n",
              " 'or': 42,\n",
              " 'like': 43,\n",
              " 'their': 44,\n",
              " 'get': 45,\n",
              " 'menu': 46,\n",
              " 'there': 47,\n",
              " 'from': 48,\n",
              " 'best': 49,\n",
              " 'staff': 50,\n",
              " 'its': 51,\n",
              " 'dinner': 52,\n",
              " 'sushi': 53,\n",
              " 'your': 54,\n",
              " 'been': 55,\n",
              " 'delicious': 56,\n",
              " 'one': 57,\n",
              " 'pizza': 58,\n",
              " 'out': 59,\n",
              " 'has': 60,\n",
              " 'atmosphere': 61,\n",
              " 'fish': 62,\n",
              " 'prices': 63,\n",
              " 'nice': 64,\n",
              " 'excellent': 65,\n",
              " 'here': 66,\n",
              " 'about': 67,\n",
              " 'more': 68,\n",
              " 'when': 69,\n",
              " 'which': 70,\n",
              " 'drinks': 71,\n",
              " 'bar': 72,\n",
              " 'us': 73,\n",
              " 'what': 74,\n",
              " 'some': 75,\n",
              " 'table': 76,\n",
              " 'would': 77,\n",
              " 'dishes': 78,\n",
              " 'only': 79,\n",
              " 'too': 80,\n",
              " 'friendly': 81,\n",
              " 'even': 82,\n",
              " 'dont': 83,\n",
              " 'by': 84,\n",
              " 'go': 85,\n",
              " 'always': 86,\n",
              " 'wait': 87,\n",
              " 'no': 88,\n",
              " 'really': 89,\n",
              " 'just': 90,\n",
              " 'fresh': 91,\n",
              " 'meal': 92,\n",
              " 'chicken': 93,\n",
              " 'price': 94,\n",
              " 'can': 95,\n",
              " 'than': 96,\n",
              " 'well': 97,\n",
              " 'while': 98,\n",
              " 'order': 99,\n",
              " 'lunch': 100,\n",
              " 'up': 101,\n",
              " 'decor': 102,\n",
              " 'ive': 103,\n",
              " 'made': 104,\n",
              " 'people': 105,\n",
              " 'back': 106,\n",
              " 'waiter': 107,\n",
              " 'never': 108,\n",
              " 'me': 109,\n",
              " 'portions': 110,\n",
              " 'times': 111,\n",
              " 'special': 112,\n",
              " 'will': 113,\n",
              " 'rice': 114,\n",
              " 'most': 115,\n",
              " 'quality': 116,\n",
              " 'because': 117,\n",
              " 'love': 118,\n",
              " 'little': 119,\n",
              " 'better': 120,\n",
              " 'small': 121,\n",
              " '2': 122,\n",
              " 'recommend': 123,\n",
              " 'time': 124,\n",
              " 'tuna': 125,\n",
              " 'amazing': 126,\n",
              " 'try': 127,\n",
              " 'also': 128,\n",
              " 'ordered': 129,\n",
              " 'other': 130,\n",
              " 'night': 131,\n",
              " 'being': 132,\n",
              " 'cheese': 133,\n",
              " 'dish': 134,\n",
              " 'though': 135,\n",
              " 'list': 136,\n",
              " 'over': 137,\n",
              " 'make': 138,\n",
              " 'tasty': 139,\n",
              " 'eat': 140,\n",
              " 'sauce': 141,\n",
              " 'could': 142,\n",
              " 'ambience': 143,\n",
              " 'ever': 144,\n",
              " 'then': 145,\n",
              " 'bit': 146,\n",
              " 'after': 147,\n",
              " 'sea': 148,\n",
              " 'who': 149,\n",
              " 'didnt': 150,\n",
              " 'much': 151,\n",
              " 'two': 152,\n",
              " 'got': 153,\n",
              " 'thai': 154,\n",
              " 'both': 155,\n",
              " 'do': 156,\n",
              " 'went': 157,\n",
              " 'everything': 158,\n",
              " 'restaurants': 159,\n",
              " 'sake': 160,\n",
              " 'indian': 161,\n",
              " 'attentive': 162,\n",
              " 'new': 163,\n",
              " 'served': 164,\n",
              " 'ok': 165,\n",
              " 'average': 166,\n",
              " 'seated': 167,\n",
              " 'nothing': 168,\n",
              " 'salmon': 169,\n",
              " 'selection': 170,\n",
              " 'taste': 171,\n",
              " 'however': 172,\n",
              " 'experience': 173,\n",
              " 'appetizers': 174,\n",
              " 'each': 175,\n",
              " 'hot': 176,\n",
              " 'appetizer': 177,\n",
              " 'bad': 178,\n",
              " 'wonderful': 179,\n",
              " 'cant': 180,\n",
              " 'worth': 181,\n",
              " 'cheap': 182,\n",
              " 'how': 183,\n",
              " 'first': 184,\n",
              " 'actually': 185,\n",
              " 'them': 186,\n",
              " 'way': 187,\n",
              " 'he': 188,\n",
              " 'course': 189,\n",
              " 'location': 190,\n",
              " 'â€“': 191,\n",
              " 'took': 192,\n",
              " 'before': 193,\n",
              " 'makes': 194,\n",
              " 'came': 195,\n",
              " 'dessert': 196,\n",
              " 'shrimp': 197,\n",
              " 'feel': 198,\n",
              " 'friends': 199,\n",
              " 'crab': 200,\n",
              " 'away': 201,\n",
              " 'wasnt': 202,\n",
              " 'ambiance': 203,\n",
              " 'must': 204,\n",
              " 'any': 205,\n",
              " 'such': 206,\n",
              " 'chef': 207,\n",
              " 'spicy': 208,\n",
              " 'down': 209,\n",
              " 'romantic': 210,\n",
              " 'salad': 211,\n",
              " 'looking': 212,\n",
              " 'priced': 213,\n",
              " 'large': 214,\n",
              " 'city': 215,\n",
              " 'nyc': 216,\n",
              " 'years': 217,\n",
              " 'lobster': 218,\n",
              " 'entree': 219,\n",
              " 'fantastic': 220,\n",
              " 'quite': 221,\n",
              " 'perfect': 222,\n",
              " 'around': 223,\n",
              " 'pretty': 224,\n",
              " 'still': 225,\n",
              " 'where': 226,\n",
              " 'dumplings': 227,\n",
              " 'rolls': 228,\n",
              " 'area': 229,\n",
              " 'water': 230,\n",
              " 'reservation': 231,\n",
              " 'especially': 232,\n",
              " 'reasonable': 233,\n",
              " 'glass': 234,\n",
              " 'want': 235,\n",
              " 'check': 236,\n",
              " 'three': 237,\n",
              " 'take': 238,\n",
              " 'specials': 239,\n",
              " 'ingredients': 240,\n",
              " 'without': 241,\n",
              " 'waitress': 242,\n",
              " 'say': 243,\n",
              " 'plate': 244,\n",
              " 'did': 245,\n",
              " 'highly': 246,\n",
              " 'fast': 247,\n",
              " 'tables': 248,\n",
              " 'cool': 249,\n",
              " 'last': 250,\n",
              " 'find': 251,\n",
              " 'once': 252,\n",
              " 'blue': 253,\n",
              " 'fine': 254,\n",
              " 'bill': 255,\n",
              " 'husband': 256,\n",
              " 'asked': 257,\n",
              " 'main': 258,\n",
              " '20': 259,\n",
              " 'music': 260,\n",
              " 'minutes': 261,\n",
              " 'few': 262,\n",
              " 'authentic': 263,\n",
              " 'date': 264,\n",
              " 'steak': 265,\n",
              " 'warm': 266,\n",
              " 'need': 267,\n",
              " 'right': 268,\n",
              " 'bread': 269,\n",
              " 'dining': 270,\n",
              " 'room': 271,\n",
              " 'bagels': 272,\n",
              " 'world': 273,\n",
              " 'come': 274,\n",
              " 'big': 275,\n",
              " 'sit': 276,\n",
              " 'pasta': 277,\n",
              " 'his': 278,\n",
              " 'eating': 279,\n",
              " 'youre': 280,\n",
              " 'off': 281,\n",
              " 'side': 282,\n",
              " 'decent': 283,\n",
              " 'mediocre': 284,\n",
              " 'should': 285,\n",
              " 'manager': 286,\n",
              " 'drink': 287,\n",
              " 'flavor': 288,\n",
              " 'full': 289,\n",
              " 'different': 290,\n",
              " 'fun': 291,\n",
              " 'top': 292,\n",
              " 'lot': 293,\n",
              " 'youll': 294,\n",
              " 'value': 295,\n",
              " 'slow': 296,\n",
              " 'many': 297,\n",
              " 'enjoyed': 298,\n",
              " 'reservations': 299,\n",
              " 'may': 300,\n",
              " 'waiters': 301,\n",
              " 'tried': 302,\n",
              " 'sure': 303,\n",
              " 'spot': 304,\n",
              " 'cooked': 305,\n",
              " 'half': 306,\n",
              " 'again': 307,\n",
              " 'usually': 308,\n",
              " 'fried': 309,\n",
              " 'french': 310,\n",
              " 'huge': 311,\n",
              " 'bartender': 312,\n",
              " 'am': 313,\n",
              " 'roll': 314,\n",
              " 'money': 315,\n",
              " 'expensive': 316,\n",
              " 'every': 317,\n",
              " 'said': 318,\n",
              " 'else': 319,\n",
              " 'same': 320,\n",
              " 'thats': 321,\n",
              " 'japanese': 322,\n",
              " 'couple': 323,\n",
              " 'server': 324,\n",
              " 'thing': 325,\n",
              " 'definitely': 326,\n",
              " 'yet': 327,\n",
              " 'high': 328,\n",
              " 'york': 329,\n",
              " 'cod': 330,\n",
              " 'poor': 331,\n",
              " 'into': 332,\n",
              " 'found': 333,\n",
              " 'late': 334,\n",
              " 'outside': 335,\n",
              " 'dim': 336,\n",
              " 'sum': 337,\n",
              " 'next': 338,\n",
              " 'incredible': 339,\n",
              " 'space': 340,\n",
              " 'enough': 341,\n",
              " 'horrible': 342,\n",
              " 'overpriced': 343,\n",
              " 'fabulous': 344,\n",
              " 'kind': 345,\n",
              " 'seafood': 346,\n",
              " 'cold': 347,\n",
              " 'know': 348,\n",
              " 'setting': 349,\n",
              " 'doesnt': 350,\n",
              " 'sashimi': 351,\n",
              " 'enjoy': 352,\n",
              " 'work': 353,\n",
              " 'hour': 354,\n",
              " 'bring': 355,\n",
              " 'waitstaff': 356,\n",
              " 'simple': 357,\n",
              " 'group': 358,\n",
              " 'oysters': 359,\n",
              " 'salads': 360,\n",
              " 'bagel': 361,\n",
              " 'including': 362,\n",
              " 'crowded': 363,\n",
              " 'tiny': 364,\n",
              " 'overall': 365,\n",
              " 'going': 366,\n",
              " 'party': 367,\n",
              " 'offer': 368,\n",
              " 'brunch': 369,\n",
              " 'beer': 370,\n",
              " 'beautiful': 371,\n",
              " 'crust': 372,\n",
              " 'fin': 373,\n",
              " 'eel': 374,\n",
              " 'friend': 375,\n",
              " 'although': 376,\n",
              " 'rude': 377,\n",
              " 'things': 378,\n",
              " 'less': 379,\n",
              " 'lamb': 380,\n",
              " 'favorite': 381,\n",
              " 'choice': 382,\n",
              " 'delivery': 383,\n",
              " 'im': 384,\n",
              " 'italian': 385,\n",
              " 'she': 386,\n",
              " 'yellow': 387,\n",
              " 'tail': 388,\n",
              " 'urchin': 389,\n",
              " 'busy': 390,\n",
              " 'return': 391,\n",
              " 'seems': 392,\n",
              " 'tasted': 393,\n",
              " '5': 394,\n",
              " 'left': 395,\n",
              " 'prepared': 396,\n",
              " 'expect': 397,\n",
              " 'since': 398,\n",
              " 'cuisine': 399,\n",
              " 'extremely': 400,\n",
              " 'think': 401,\n",
              " 'twice': 402,\n",
              " 'keep': 403,\n",
              " 'see': 404,\n",
              " 'prompt': 405,\n",
              " 'fan': 406,\n",
              " 'trout': 407,\n",
              " 'sitting': 408,\n",
              " 'sat': 409,\n",
              " 'almost': 410,\n",
              " 'door': 411,\n",
              " 'give': 412,\n",
              " 'considering': 413,\n",
              " 'size': 414,\n",
              " 'reviews': 415,\n",
              " 'regular': 416,\n",
              " 'wrong': 417,\n",
              " 'portion': 418,\n",
              " 'anything': 419,\n",
              " 'owner': 420,\n",
              " 'cute': 421,\n",
              " 'impressed': 422,\n",
              " 'isnt': 423,\n",
              " 'entire': 424,\n",
              " 'quick': 425,\n",
              " 'another': 426,\n",
              " 'cut': 427,\n",
              " 'ask': 428,\n",
              " 'far': 429,\n",
              " 'vegetables': 430,\n",
              " 'ny': 431,\n",
              " 'spectacular': 432,\n",
              " 'noodles': 433,\n",
              " 'places': 434,\n",
              " 'beef': 435,\n",
              " 'look': 436,\n",
              " 'bland': 437,\n",
              " 'pricey': 438,\n",
              " 'part': 439,\n",
              " 'having': 440,\n",
              " 'itself': 441,\n",
              " 'smaller': 442,\n",
              " 'management': 443,\n",
              " 'wife': 444,\n",
              " 'sandwich': 445,\n",
              " 'style': 446,\n",
              " 'pork': 447,\n",
              " 'milk': 448,\n",
              " 'use': 449,\n",
              " 'fancy': 450,\n",
              " 'saw': 451,\n",
              " 'sweet': 452,\n",
              " 'happy': 453,\n",
              " 'sometimes': 454,\n",
              " 'house': 455,\n",
              " 'long': 456,\n",
              " 'packed': 457,\n",
              " 'these': 458,\n",
              " 'life': 459,\n",
              " 'real': 460,\n",
              " 'empty': 461,\n",
              " 'neighborhood': 462,\n",
              " 'coming': 463,\n",
              " 'terrible': 464,\n",
              " 'family': 465,\n",
              " 'seen': 466,\n",
              " 'mind': 467,\n",
              " 'end': 468,\n",
              " 'offered': 469,\n",
              " 'easily': 470,\n",
              " 'might': 471,\n",
              " 'often': 472,\n",
              " 'killer': 473,\n",
              " 'mackeral': 474,\n",
              " 'jellyfish': 475,\n",
              " 'scallop': 476,\n",
              " 'tasting': 477,\n",
              " 'casual': 478,\n",
              " 'front': 479,\n",
              " 'live': 480,\n",
              " 'extensive': 481,\n",
              " 'those': 482,\n",
              " 'several': 483,\n",
              " '100': 484,\n",
              " 'least': 485,\n",
              " 'yes': 486,\n",
              " 'serve': 487,\n",
              " 'looked': 488,\n",
              " 'seat': 489,\n",
              " 'does': 490,\n",
              " 'deal': 491,\n",
              " 'during': 492,\n",
              " 'comes': 493,\n",
              " 'reasonably': 494,\n",
              " 'rather': 495,\n",
              " 'expertly': 496,\n",
              " 'soho': 497,\n",
              " 'fluke': 498,\n",
              " 'bream': 499,\n",
              " 'sardine': 500,\n",
              " 'monk': 501,\n",
              " 'roe': 502,\n",
              " 'varity': 503,\n",
              " 'toro': 504,\n",
              " 'close': 505,\n",
              " 'simply': 506,\n",
              " 'unique': 507,\n",
              " 'desserts': 508,\n",
              " 'wines': 509,\n",
              " 'cream': 510,\n",
              " 'village': 511,\n",
              " 'outstanding': 512,\n",
              " '1': 513,\n",
              " 'home': 514,\n",
              " 'piece': 515,\n",
              " 'received': 516,\n",
              " 'completely': 517,\n",
              " 'bottle': 518,\n",
              " 'either': 519,\n",
              " 'fact': 520,\n",
              " 'pay': 521,\n",
              " 'id': 522,\n",
              " 'feeling': 523,\n",
              " 'absolutely': 524,\n",
              " 'pieces': 525,\n",
              " 'chinese': 526,\n",
              " 'white': 527,\n",
              " 'seating': 528,\n",
              " 'pad': 529,\n",
              " 'yummy': 530,\n",
              " 'except': 531,\n",
              " 'eggs': 532,\n",
              " 'probably': 533,\n",
              " 'put': 534,\n",
              " 'manhattan': 535,\n",
              " '7': 536,\n",
              " 'typical': 537,\n",
              " 'entrees': 538,\n",
              " 'tip': 539,\n",
              " 'spend': 540,\n",
              " 'forget': 541,\n",
              " 'problem': 542,\n",
              " 'liked': 543,\n",
              " 'eaten': 544,\n",
              " 'tastes': 545,\n",
              " 'getting': 546,\n",
              " 'wouldnt': 547,\n",
              " 'helpful': 548,\n",
              " 'thin': 549,\n",
              " 'consistently': 550,\n",
              " 'anywhere': 551,\n",
              " 'limited': 552,\n",
              " 'soggy': 553,\n",
              " 'spice': 554,\n",
              " 'bistro': 555,\n",
              " 'gave': 556,\n",
              " 'someone': 557,\n",
              " 'beers': 558,\n",
              " 'fix': 559,\n",
              " 'something': 560,\n",
              " 'chocolate': 561,\n",
              " 'despite': 562,\n",
              " 'through': 563,\n",
              " 'soup': 564,\n",
              " 'care': 565,\n",
              " 'worst': 566,\n",
              " 'clean': 567,\n",
              " 'upon': 568,\n",
              " 'sharing': 569,\n",
              " 'looks': 570,\n",
              " 'whole': 571,\n",
              " 'okay': 572,\n",
              " 'day': 573,\n",
              " 'town': 574,\n",
              " 'cost': 575,\n",
              " 'scallops': 576,\n",
              " 'free': 577,\n",
              " 'selections': 578,\n",
              " 'told': 579,\n",
              " 'glasses': 580,\n",
              " 'spent': 581,\n",
              " 'rest': 582,\n",
              " 'slice': 583,\n",
              " 'until': 584,\n",
              " 'beat': 585,\n",
              " 'awesome': 586,\n",
              " 'vibe': 587,\n",
              " 'pleasant': 588,\n",
              " 'plus': 589,\n",
              " 'wont': 590,\n",
              " 'forgot': 591,\n",
              " 'toast': 592,\n",
              " 'dark': 593,\n",
              " 'complimentary': 594,\n",
              " 'pot': 595,\n",
              " 'garlic': 596,\n",
              " 'toppings': 597,\n",
              " 'gone': 598,\n",
              " 'customer': 599,\n",
              " 'terrific': 600,\n",
              " 'interesting': 601,\n",
              " 'old': 602,\n",
              " 'instead': 603,\n",
              " 'nights': 604,\n",
              " 'previous': 605,\n",
              " 'fries': 606,\n",
              " 'disappointed': 607,\n",
              " 'person': 608,\n",
              " 'arrived': 609,\n",
              " 'meat': 610,\n",
              " 'paid': 611,\n",
              " 'walked': 612,\n",
              " 'naan': 613,\n",
              " 'changed': 614,\n",
              " 'lack': 615,\n",
              " 'red': 616,\n",
              " 'delivered': 617,\n",
              " 'expected': 618,\n",
              " 'her': 619,\n",
              " 'duck': 620,\n",
              " 'sides': 621,\n",
              " 'below': 622,\n",
              " 'open': 623,\n",
              " 'touch': 624,\n",
              " 'jazz': 625,\n",
              " 'exceptional': 626,\n",
              " 'chinatown': 627,\n",
              " '4': 628,\n",
              " 'above': 629,\n",
              " 'second': 630,\n",
              " 'mix': 631,\n",
              " 'tempura': 632,\n",
              " 'intimate': 633,\n",
              " 'various': 634,\n",
              " '10': 635,\n",
              " 'cafe': 636,\n",
              " 'incredibly': 637,\n",
              " 'curry': 638,\n",
              " 'lots': 639,\n",
              " 'pancakes': 640,\n",
              " 'given': 641,\n",
              " 'cannot': 642,\n",
              " 'quantity': 643,\n",
              " 'fare': 644,\n",
              " 'foods': 645,\n",
              " 'business': 646,\n",
              " 'dogs': 647,\n",
              " 'hand': 648,\n",
              " 'servers': 649,\n",
              " 'shows': 650,\n",
              " 'cramped': 651,\n",
              " 'kitchen': 652,\n",
              " 'weve': 653,\n",
              " '15': 654,\n",
              " 'summer': 655,\n",
              " 'now': 656,\n",
              " 'thought': 657,\n",
              " 'plain': 658,\n",
              " 'pastas': 659,\n",
              " 'rays': 660,\n",
              " 'basic': 661,\n",
              " 'ordering': 662,\n",
              " 'visit': 663,\n",
              " 'dry': 664,\n",
              " 'secret': 665,\n",
              " 'name': 666,\n",
              " 'suggestions': 667,\n",
              " 'rushed': 668,\n",
              " 'save': 669,\n",
              " 'street': 670,\n",
              " 'owners': 671,\n",
              " 'fixe': 672,\n",
              " 'per': 673,\n",
              " 'finally': 674,\n",
              " 'sizes': 675,\n",
              " 'please': 676,\n",
              " 'included': 677,\n",
              " 'started': 678,\n",
              " 'ate': 679,\n",
              " 'super': 680,\n",
              " 'low': 681,\n",
              " 'etc': 682,\n",
              " 'barely': 683,\n",
              " 'lovely': 684,\n",
              " 'presented': 685,\n",
              " 'range': 686,\n",
              " '3': 687,\n",
              " 'butter': 688,\n",
              " 'delicate': 689,\n",
              " 'evening': 690,\n",
              " 'soft': 691,\n",
              " 'garden': 692,\n",
              " 'gets': 693,\n",
              " 'include': 694,\n",
              " 'conversation': 695,\n",
              " 'loud': 696,\n",
              " 'help': 697,\n",
              " 'pastrami': 698,\n",
              " 'fatty': 699,\n",
              " 'loved': 700,\n",
              " 'bathroom': 701,\n",
              " 'slightly': 702,\n",
              " 'prix': 703,\n",
              " 'types': 704,\n",
              " 'pepper': 705,\n",
              " 'mean': 706,\n",
              " 'mussels': 707,\n",
              " 'serving': 708,\n",
              " 'comfortable': 709,\n",
              " 'outdoor': 710,\n",
              " 'unless': 711,\n",
              " 'salty': 712,\n",
              " 'stuff': 713,\n",
              " 'trip': 714,\n",
              " 'wish': 715,\n",
              " 'line': 716,\n",
              " 'everyone': 717,\n",
              " 'diner': 718,\n",
              " 'offers': 719,\n",
              " 'oily': 720,\n",
              " 'bass': 721,\n",
              " 'courses': 722,\n",
              " 'variety': 723,\n",
              " 'surprise': 724,\n",
              " 'needs': 725,\n",
              " 'goat': 726,\n",
              " 'tea': 727,\n",
              " 'past': 728,\n",
              " 'affordable': 729,\n",
              " 'juice': 730,\n",
              " 'sliced': 731,\n",
              " 'waiting': 732,\n",
              " 'sandwiches': 733,\n",
              " 'accomodating': 734,\n",
              " 'chefs': 735,\n",
              " 'tomato': 736,\n",
              " 'scallion': 737,\n",
              " 'sichuan': 738,\n",
              " 'pick': 739,\n",
              " 'la': 740,\n",
              " 'assortment': 741,\n",
              " 'cozy': 742,\n",
              " 'suggest': 743,\n",
              " 'certainly': 744,\n",
              " 'presentation': 745,\n",
              " 'felt': 746,\n",
              " 'modern': 747,\n",
              " 'lived': 748,\n",
              " 'waste': 749,\n",
              " 'inside': 750,\n",
              " 'tend': 751,\n",
              " 'particular': 752,\n",
              " 'share': 753,\n",
              " 'avenue': 754,\n",
              " 'lemon': 755,\n",
              " 'amount': 756,\n",
              " 'pita': 757,\n",
              " 'relaxed': 758,\n",
              " 'mushrooms': 759,\n",
              " 'believe': 760,\n",
              " 'prawns': 761,\n",
              " 'buffet': 762,\n",
              " 'boyfriend': 763,\n",
              " 'relax': 764,\n",
              " 'oil': 765,\n",
              " 'beyond': 766,\n",
              " 'choices': 767,\n",
              " 'extra': 768,\n",
              " 'ravioli': 769,\n",
              " 'greatest': 770,\n",
              " 'orsay': 771,\n",
              " 'relaxing': 772,\n",
              " 'saturday': 773,\n",
              " 'busboy': 774,\n",
              " 'filet': 775,\n",
              " 'host': 776,\n",
              " 'items': 777,\n",
              " 'theres': 778,\n",
              " 'subpar': 779,\n",
              " 'halibut': 780,\n",
              " 'enjoying': 781,\n",
              " 'type': 782,\n",
              " 'fair': 783,\n",
              " 'whether': 784,\n",
              " 'occasion': 785,\n",
              " 'call': 786,\n",
              " 'mushroom': 787,\n",
              " 'remember': 788,\n",
              " 'view': 789,\n",
              " 'burger': 790,\n",
              " 'eggplant': 791,\n",
              " 'meats': 792,\n",
              " '6': 793,\n",
              " 'turned': 794,\n",
              " 'particularly': 795,\n",
              " 'couldnt': 796,\n",
              " 'horribly': 797,\n",
              " 'meals': 798,\n",
              " 'east': 799,\n",
              " 'birthday': 800,\n",
              " 'week': 801,\n",
              " 'girlfriend': 802,\n",
              " 'customers': 803,\n",
              " 'professional': 804,\n",
              " 'guest': 805,\n",
              " 'thier': 806,\n",
              " 'theyre': 807,\n",
              " 'saul': 808,\n",
              " 'lox': 809,\n",
              " 'personal': 810,\n",
              " 'agree': 811,\n",
              " 'potato': 812,\n",
              " 'chips': 813,\n",
              " 'inexpensive': 814,\n",
              " 'used': 815,\n",
              " 'bucks': 816,\n",
              " 'seattle': 817,\n",
              " 'reviewer': 818,\n",
              " 'assorted': 819,\n",
              " 'banana': 820,\n",
              " 'ago': 821,\n",
              " 'understand': 822,\n",
              " 'hadnt': 823,\n",
              " 'breakfast': 824,\n",
              " 'design': 825,\n",
              " 'light': 826,\n",
              " 'seem': 827,\n",
              " 'tender': 828,\n",
              " 'quiet': 829,\n",
              " 'means': 830,\n",
              " 'aside': 831,\n",
              " 'sense': 832,\n",
              " 'chai': 833,\n",
              " 'guests': 834,\n",
              " 'dine': 835,\n",
              " 'request': 836,\n",
              " '45': 837,\n",
              " 'four': 838,\n",
              " 'five': 839,\n",
              " 'paneer': 840,\n",
              " 'remained': 841,\n",
              " 'weekends': 842,\n",
              " 'potential': 843,\n",
              " 'coffee': 844,\n",
              " 'caviar': 845,\n",
              " 'chance': 846,\n",
              " 'eats': 847,\n",
              " 'smile': 848,\n",
              " 'plentiful': 849,\n",
              " 'mizu': 850,\n",
              " 'anyone': 851,\n",
              " 'supposed': 852,\n",
              " 'trying': 853,\n",
              " 'hostess': 854,\n",
              " 'martini': 855,\n",
              " 'matter': 856,\n",
              " 'knows': 857,\n",
              " 'downtown': 858,\n",
              " 'called': 859,\n",
              " 'myself': 860,\n",
              " 'spices': 861,\n",
              " 'onions': 862,\n",
              " 'roti': 863,\n",
              " 'impressive': 864,\n",
              " 'lovers': 865,\n",
              " 'margaritas': 866,\n",
              " 'totally': 867,\n",
              " 'st': 868,\n",
              " 'uws': 869,\n",
              " 'arrogant': 870,\n",
              " 'noodle': 871,\n",
              " 'roast': 872,\n",
              " 'hard': 873,\n",
              " 'crispy': 874,\n",
              " 'soy': 875,\n",
              " 'counter': 876,\n",
              " 'behind': 877,\n",
              " 'japan': 878,\n",
              " 'disgusting': 879,\n",
              " 'nearly': 880,\n",
              " 'taking': 881,\n",
              " 'reason': 882,\n",
              " '25': 883,\n",
              " 'fairly': 884,\n",
              " 'ceviche': 885,\n",
              " 'watering': 886,\n",
              " 'weird': 887,\n",
              " 'kept': 888,\n",
              " 'filling': 889,\n",
              " 'classic': 890,\n",
              " 'watery': 891,\n",
              " 'poured': 892,\n",
              " 'suggested': 893,\n",
              " 'read': 894,\n",
              " 'freshness': 895,\n",
              " 'point': 896,\n",
              " 'somosas': 897,\n",
              " 'chole': 898,\n",
              " 'dhosas': 899,\n",
              " 'dhal': 900,\n",
              " 'kinda': 901,\n",
              " 'dissapointing': 902,\n",
              " 'entertainment': 903,\n",
              " 'shared': 904,\n",
              " 'making': 905,\n",
              " 'done': 906,\n",
              " 'joint': 907,\n",
              " 'split': 908,\n",
              " 'putting': 909,\n",
              " 'containers': 910,\n",
              " 'topnotch': 911,\n",
              " 'exotic': 912,\n",
              " 'start': 913,\n",
              " 'hummus': 914,\n",
              " 'comfort': 915,\n",
              " 'midtown': 916,\n",
              " 'unobtrusive': 917,\n",
              " 'bacon': 918,\n",
              " 'leave': 919,\n",
              " 'kickass': 920,\n",
              " 'boiling': 921,\n",
              " 'sunken': 922,\n",
              " 'surface': 923,\n",
              " 'platters': 924,\n",
              " 'under': 925,\n",
              " 'comment': 926,\n",
              " 'udon': 927,\n",
              " 'hang': 928,\n",
              " 'wow': 929,\n",
              " 'congee': 930,\n",
              " 'option': 931,\n",
              " 'shredded': 932,\n",
              " 'american': 933,\n",
              " 'platter': 934,\n",
              " 'elegant': 935,\n",
              " 'oh': 936,\n",
              " 'experienced': 937,\n",
              " 'spreads': 938,\n",
              " 'ordinary': 939,\n",
              " 'item': 940,\n",
              " 'gem': 941,\n",
              " 'run': 942,\n",
              " 'freshest': 943,\n",
              " 'able': 944,\n",
              " 'walk': 945,\n",
              " 'pudding': 946,\n",
              " 'bbq': 947,\n",
              " 'seasoned': 948,\n",
              " 'pie': 949,\n",
              " 'otherwise': 950,\n",
              " 'creative': 951,\n",
              " 'overbearing': 952,\n",
              " 'awsome': 953,\n",
              " 'mouth': 954,\n",
              " 'add': 955,\n",
              " 'trained': 956,\n",
              " 'sleek': 957,\n",
              " 'west': 958,\n",
              " 'cokes': 959,\n",
              " '5500': 960,\n",
              " 'miss': 961,\n",
              " 'sunday': 962,\n",
              " 'trouble': 963,\n",
              " 'awful': 964,\n",
              " 'veal': 965,\n",
              " 'soon': 966,\n",
              " 'consider': 967,\n",
              " 'lacked': 968,\n",
              " 'similar': 969,\n",
              " 'employees': 970,\n",
              " '160': 971,\n",
              " 'scene': 972,\n",
              " 'annoying': 973,\n",
              " 'yorkers': 974,\n",
              " 'mention': 975,\n",
              " 'terms': 976,\n",
              " 'filled': 977,\n",
              " 'word': 978,\n",
              " 'bite': 979,\n",
              " 'salt': 980,\n",
              " 'promised': 981,\n",
              " 'unfriendly': 982,\n",
              " 'guy': 983,\n",
              " 'him': 984,\n",
              " 'likely': 985,\n",
              " 'ourselves': 986,\n",
              " 'edamames': 987,\n",
              " 'star': 988,\n",
              " 'fusion': 989,\n",
              " 'establishment': 990,\n",
              " 'belly': 991,\n",
              " 'korma': 992,\n",
              " 'solid': 993,\n",
              " 'along': 994,\n",
              " 'werent': 995,\n",
              " 'diverse': 996,\n",
              " 'interior': 997,\n",
              " 'known': 998,\n",
              " 'potatoes': 999,\n",
              " 'early': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PevEBEvqjL4w"
      },
      "outputs": [],
      "source": [
        "# #load word embeddings from gensim api\n",
        "# word2vec = api.load(\"word2vec-google-news-300\")\n",
        "# embedding_dim = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_gx5YAsq5zs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84594fcf-345b-449d-e9c1-9b2d8ce8824f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got embedding for 3721 words\n",
            "Embeddings not found for 461 words\n"
          ]
        }
      ],
      "source": [
        "# preparation of embedding matrix (tokens,embedding_dim)\n",
        "n_tokens=len(tokenizer.word_index)+1\n",
        "embedding_matrix=np.zeros((n_tokens,embedding_dim))\n",
        "hits=miss=0\n",
        "\n",
        "# filling the embedding matrix\n",
        "for word,i in tokenizer.word_index.items():\n",
        "  word_embedding=None\n",
        "\n",
        "  try:\n",
        "    word_embedding=word2vec[word]\n",
        "  except Exception as e:\n",
        "    pass\n",
        "\n",
        "  if word_embedding is not None:\n",
        "    embedding_matrix[i]=word_embedding\n",
        "    hits+=1\n",
        "  else:\n",
        "    miss+=1\n",
        "\n",
        "print(f\"Got embedding for {hits} words\")\n",
        "print(f\"Embeddings not found for {miss} words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Bahdanau Attention"
      ],
      "metadata": {
        "id": "Yhh83USp69I0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self,units):\n",
        "    super(Attention,self).__init__(name='Attention')\n",
        "\n",
        "    self.units=units\n",
        "    self.W1=tf.keras.layers.Dense(self.units)\n",
        "    self.W2=tf.keras.layers.Dense(self.units)\n",
        "    self.V=tf.keras.layers.Dense(1)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({'units': self.units, })\n",
        "    return config\n",
        "\n",
        "  def call(self,query,keys,flag=False):\n",
        "    \"\"\"\n",
        "    query: (batch_size,embedding_dim)\n",
        "    keys : (batch_size,max_len,embedding_dim)\n",
        "    \"\"\"\n",
        "\n",
        "    # expanding the query along the time axis ==> query: (batch_size,1,embedding_dim)\n",
        "    if not flag:\n",
        "      query_time_axis=tf.expand_dims(query,1)\n",
        "    else:\n",
        "      query_time_axis=query\n",
        "\n",
        "    # calculating the attention scores\n",
        "    i=self.W1(query_time_axis)    # i=(batch_size,units)\n",
        "    j=self.W2(keys)               # j=(batch_size,max_len,units)\n",
        "\n",
        "\n",
        "    # adding i and j (i will get broadcasted to match j's dimension and the result will be (batch_size,max_len,units) ) and applying tanh\n",
        "    k=tf.nn.tanh(i+j)\n",
        "    # passing the result to the get the attention scores (batch_size,max_len,1)\n",
        "    scores=self.V(k)\n",
        "    # applying softmax along axis=1\n",
        "    attention_weights=tf.nn.softmax(scores,axis=1)\n",
        "\n",
        "    # getting the context vector (batch_size,max_len,1) * (batch_size,max_len,embedding_dim) = (batch_size,max_len,embedding_dim) attention_weights tensor will get broadcasted automatically\n",
        "    context_vector=attention_weights*keys\n",
        "    # summing up along the max_len axis\n",
        "    context_vector=tf.reduce_sum(context_vector,axis=1)   # context_vector: (batch_size,embedding_dim)\n",
        "\n",
        "    return context_vector,attention_weights"
      ],
      "metadata": {
        "id": "TfmfAD0RCEfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "SO0LOLfZJKQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the embedding layer (we have our own word2vec embedding so we need to specify the embeding matrix)\n",
        "embedding_layer=Embedding(n_tokens,\n",
        "                          embedding_dim,\n",
        "                          embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix), # initializing with the word2vec embeddings\n",
        "                          trainable=False,\n",
        "                          name='embedding_layer')\n",
        "\n",
        "# defining the review input (the input shape is 20, which means each review should be 20 words long)\n",
        "review_input=tf.keras.Input(shape=(20,),dtype=\"float64\",name='review_input_text')\n",
        "\n",
        "# defining the aspect input  (the input shape is 2, which means there should be 2 aspects)\n",
        "aspect_input=tf.keras.Input(shape=(2,),dtype='float64',name='aspect_input_text')\n",
        "\n",
        "# passing the review and aspects to the embdding layer\n",
        "review_embedding=embedding_layer(review_input)\n",
        "\n",
        "aspect_embedding=embedding_layer(aspect_input)\n",
        "\n",
        "# passing the review_embeddings to a GRU layer\n",
        "gru_review,_= tf.keras.layers.GRU(64,return_sequences=True,return_state=True)(review_embedding)\n",
        "\n",
        "# passing the aspect_embedding to the GRU layer\n",
        "_,gru_aspect= tf.keras.layers.GRU(64,return_sequences=True,return_state=True)(aspect_embedding)\n",
        "\n",
        "# passing the aspect and reviews from gru layers to attention layer\n",
        "context_vector,attention_weights= Attention(128)(gru_aspect,gru_review)\n",
        "\n",
        "# passing the context vectors to the dense layers\n",
        "dense64_output=tf.keras.layers.Dense(64,activation='selu')(context_vector)\n",
        "dense16_output=tf.keras.layers.Dense(16,activation='selu')(dense64_output)\n",
        "output=tf.keras.layers.Dense(3,activation='softmax')(dense16_output)\n",
        "\n",
        "# creating the model\n",
        "model= tf.keras.Model(inputs=[review_input,aspect_input],outputs=output)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"],run_eagerly=True)\n"
      ],
      "metadata": {
        "id": "DGm5XwLA9lAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mJIqSP1DBsc",
        "outputId": "4730f41a-33c2-4706-ce10-f70b61588f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " aspect_input_text (InputLa  [(None, 2)]                  0         []                            \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " review_input_text (InputLa  [(None, 20)]                 0         []                            \n",
            " yer)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_layer (Embedding  multiple                     1254900   ['review_input_text[0][0]',   \n",
            " )                                                                   'aspect_input_text[0][0]']   \n",
            "                                                                                                  \n",
            " gru_27 (GRU)                [(None, 2, 64),              70272     ['embedding_layer[1][0]']     \n",
            "                              (None, 64)]                                                         \n",
            "                                                                                                  \n",
            " gru_26 (GRU)                [(None, 20, 64),             70272     ['embedding_layer[0][0]']     \n",
            "                              (None, 64)]                                                         \n",
            "                                                                                                  \n",
            " Attention (Attention)       ((None, 64),                 16769     ['gru_27[0][1]',              \n",
            "                              (None, 20, 1))                         'gru_26[0][0]']              \n",
            "                                                                                                  \n",
            " dense_54 (Dense)            (None, 64)                   4160      ['Attention[0][0]']           \n",
            "                                                                                                  \n",
            " dense_55 (Dense)            (None, 16)                   1040      ['dense_54[0][0]']            \n",
            "                                                                                                  \n",
            " dense_56 (Dense)            (None, 3)                    51        ['dense_55[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1417464 (5.41 MB)\n",
            "Trainable params: 162564 (635.02 KB)\n",
            "Non-trainable params: 1254900 (4.79 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Test Data prep"
      ],
      "metadata": {
        "id": "rgrV1nNkLnQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the training reviews to review sequences\n",
        "x_train_reviews=tokenizer.texts_to_sequences(x_train['sentence'])\n",
        "# padding the review sequences\n",
        "x_train_reviews_padded=tf.keras.preprocessing.sequence.pad_sequences(x_train_reviews,maxlen=20)\n",
        "\n",
        "# converting the traning aspects to aspect sequences\n",
        "x_train_aspects=tokenizer.texts_to_sequences(x_train['term'])\n",
        "x_train_aspects_padded=tf.keras.preprocessing.sequence.pad_sequences(x_train_aspects,maxlen=2)\n",
        "\n",
        "# train label processing\n",
        "y_train= tf.keras.utils.to_categorical(y_train,num_classes=3)\n"
      ],
      "metadata": {
        "id": "8M6kSLIUQpoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the validation reviews to review sequences\n",
        "x_val_reviews=tokenizer.texts_to_sequences(x_val['sentence'])\n",
        "# padding the review sequences\n",
        "x_val_reviews_padded=tf.keras.preprocessing.sequence.pad_sequences(x_val_reviews,maxlen=20)\n",
        "\n",
        "# converting the validation aspects to aspect sequences\n",
        "x_val_aspects=tokenizer.texts_to_sequences(x_val['term'])\n",
        "x_val_aspects_padded=tf.keras.preprocessing.sequence.pad_sequences(x_val_aspects,maxlen=2)\n",
        "\n",
        "# val label processing\n",
        "y_val= tf.keras.utils.to_categorical(y_val,num_classes=3)"
      ],
      "metadata": {
        "id": "Ph2kcmbUTDeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the test reviews to review sequences\n",
        "x_test_reviews=tokenizer.texts_to_sequences(x_test['sentence'])\n",
        "# padding the review sequences\n",
        "x_test_reviews_padded=tf.keras.preprocessing.sequence.pad_sequences(x_test_reviews,maxlen=20)\n",
        "\n",
        "# converting the test aspects to aspect sequences\n",
        "x_test_aspects=tokenizer.texts_to_sequences(x_test['term'])\n",
        "x_test_aspects_padded=tf.keras.preprocessing.sequence.pad_sequences(x_test_aspects,maxlen=2)"
      ],
      "metadata": {
        "id": "zHSqAnJnTTBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorboard call back\n",
        "log_dir = \"logs/26th_march\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# save model callback\n",
        "save_model = tf.keras.callbacks.ModelCheckpoint(filepath='aspect_based_sa.h5',\n",
        "  monitor='val_acc',\n",
        "  mode='max',\n",
        "  save_weights_only=True,\n",
        "  save_best_only=True,\n",
        "  verbose=1\n",
        ")\n",
        "\n",
        "# early stopping callback\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=10)\n",
        "\n",
        "callbacks = [save_model, es]"
      ],
      "metadata": {
        "id": "ZSm5IipefJ-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "history=model.fit(\n",
        "          [x_train_reviews_padded,x_train_aspects_padded],\n",
        "          y_train,\n",
        "          batch_size=64,\n",
        "          epochs=300,\n",
        "          validation_data=([x_val_reviews_padded,x_val_aspects_padded],y_val),\n",
        "          callbacks=callbacks,\n",
        "          shuffle=True\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9EL9aWOfKmu",
        "outputId": "9d93dc7c-7d42-4886-dc57-3b5c760e852a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.8663 - acc: 0.6133\n",
            "Epoch 1: val_acc improved from -inf to 0.65391, saving model to aspect_based_sa.h5\n",
            "59/59 [==============================] - 103s 2s/step - loss: 0.8663 - acc: 0.6133 - val_loss: 0.7706 - val_acc: 0.6539\n",
            "Epoch 2/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.6866 - acc: 0.7149\n",
            "Epoch 2: val_acc improved from 0.65391 to 0.69378, saving model to aspect_based_sa.h5\n",
            "59/59 [==============================] - 15s 262ms/step - loss: 0.6866 - acc: 0.7149 - val_loss: 0.7060 - val_acc: 0.6938\n",
            "Epoch 3/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.6163 - acc: 0.7375\n",
            "Epoch 3: val_acc improved from 0.69378 to 0.71691, saving model to aspect_based_sa.h5\n",
            "59/59 [==============================] - 16s 267ms/step - loss: 0.6163 - acc: 0.7375 - val_loss: 0.6776 - val_acc: 0.7169\n",
            "Epoch 4/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.5556 - acc: 0.7649\n",
            "Epoch 4: val_acc improved from 0.71691 to 0.72648, saving model to aspect_based_sa.h5\n",
            "59/59 [==============================] - 16s 276ms/step - loss: 0.5556 - acc: 0.7649 - val_loss: 0.6584 - val_acc: 0.7265\n",
            "Epoch 5/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.4949 - acc: 0.8013\n",
            "Epoch 5: val_acc did not improve from 0.72648\n",
            "59/59 [==============================] - 16s 268ms/step - loss: 0.4949 - acc: 0.8013 - val_loss: 0.7248 - val_acc: 0.7257\n",
            "Epoch 6/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.4510 - acc: 0.8146\n",
            "Epoch 6: val_acc improved from 0.72648 to 0.73844, saving model to aspect_based_sa.h5\n",
            "59/59 [==============================] - 16s 269ms/step - loss: 0.4510 - acc: 0.8146 - val_loss: 0.6828 - val_acc: 0.7384\n",
            "Epoch 7/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.4046 - acc: 0.8404\n",
            "Epoch 7: val_acc improved from 0.73844 to 0.74960, saving model to aspect_based_sa.h5\n",
            "59/59 [==============================] - 17s 289ms/step - loss: 0.4046 - acc: 0.8404 - val_loss: 0.7032 - val_acc: 0.7496\n",
            "Epoch 8/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.3707 - acc: 0.8556\n",
            "Epoch 8: val_acc improved from 0.74960 to 0.75837, saving model to aspect_based_sa.h5\n",
            "59/59 [==============================] - 17s 278ms/step - loss: 0.3707 - acc: 0.8556 - val_loss: 0.6957 - val_acc: 0.7584\n",
            "Epoch 9/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.3378 - acc: 0.8707\n",
            "Epoch 9: val_acc did not improve from 0.75837\n",
            "59/59 [==============================] - 17s 284ms/step - loss: 0.3378 - acc: 0.8707 - val_loss: 0.6971 - val_acc: 0.7512\n",
            "Epoch 10/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.3063 - acc: 0.8835\n",
            "Epoch 10: val_acc did not improve from 0.75837\n",
            "59/59 [==============================] - 16s 271ms/step - loss: 0.3063 - acc: 0.8835 - val_loss: 0.7336 - val_acc: 0.7568\n",
            "Epoch 11/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.2894 - acc: 0.8896\n",
            "Epoch 11: val_acc improved from 0.75837 to 0.76555, saving model to aspect_based_sa.h5\n",
            "59/59 [==============================] - 17s 293ms/step - loss: 0.2894 - acc: 0.8896 - val_loss: 0.7733 - val_acc: 0.7656\n",
            "Epoch 12/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.2596 - acc: 0.9019\n",
            "Epoch 12: val_acc did not improve from 0.76555\n",
            "59/59 [==============================] - 16s 266ms/step - loss: 0.2596 - acc: 0.9019 - val_loss: 0.7747 - val_acc: 0.7632\n",
            "Epoch 13/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.2338 - acc: 0.9109\n",
            "Epoch 13: val_acc improved from 0.76555 to 0.77033, saving model to aspect_based_sa.h5\n",
            "59/59 [==============================] - 16s 267ms/step - loss: 0.2338 - acc: 0.9109 - val_loss: 0.8155 - val_acc: 0.7703\n",
            "Epoch 14/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.2061 - acc: 0.9223\n",
            "Epoch 14: val_acc did not improve from 0.77033\n",
            "59/59 [==============================] - 17s 284ms/step - loss: 0.2061 - acc: 0.9223 - val_loss: 0.8394 - val_acc: 0.7687\n",
            "Epoch 15/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.1898 - acc: 0.9285\n",
            "Epoch 15: val_acc improved from 0.77033 to 0.78230, saving model to aspect_based_sa.h5\n",
            "59/59 [==============================] - 15s 262ms/step - loss: 0.1898 - acc: 0.9285 - val_loss: 0.8600 - val_acc: 0.7823\n",
            "Epoch 16/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.1741 - acc: 0.9335\n",
            "Epoch 16: val_acc did not improve from 0.78230\n",
            "59/59 [==============================] - 16s 277ms/step - loss: 0.1741 - acc: 0.9335 - val_loss: 0.9013 - val_acc: 0.7711\n",
            "Epoch 17/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.1498 - acc: 0.9447\n",
            "Epoch 17: val_acc did not improve from 0.78230\n",
            "59/59 [==============================] - 16s 265ms/step - loss: 0.1498 - acc: 0.9447 - val_loss: 0.9823 - val_acc: 0.7791\n",
            "Epoch 18/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.1283 - acc: 0.9513\n",
            "Epoch 18: val_acc did not improve from 0.78230\n",
            "59/59 [==============================] - 17s 280ms/step - loss: 0.1283 - acc: 0.9513 - val_loss: 1.0336 - val_acc: 0.7743\n",
            "Epoch 19/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.1260 - acc: 0.9543\n",
            "Epoch 19: val_acc did not improve from 0.78230\n",
            "59/59 [==============================] - 16s 269ms/step - loss: 0.1260 - acc: 0.9543 - val_loss: 1.0810 - val_acc: 0.7671\n",
            "Epoch 20/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.1123 - acc: 0.9559\n",
            "Epoch 20: val_acc did not improve from 0.78230\n",
            "59/59 [==============================] - 16s 266ms/step - loss: 0.1123 - acc: 0.9559 - val_loss: 1.0919 - val_acc: 0.7640\n",
            "Epoch 21/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.1090 - acc: 0.9598\n",
            "Epoch 21: val_acc did not improve from 0.78230\n",
            "59/59 [==============================] - 16s 275ms/step - loss: 0.1090 - acc: 0.9598 - val_loss: 1.1070 - val_acc: 0.7767\n",
            "Epoch 22/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0958 - acc: 0.9641\n",
            "Epoch 22: val_acc did not improve from 0.78230\n",
            "59/59 [==============================] - 16s 271ms/step - loss: 0.0958 - acc: 0.9641 - val_loss: 1.1730 - val_acc: 0.7719\n",
            "Epoch 23/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0879 - acc: 0.9678\n",
            "Epoch 23: val_acc did not improve from 0.78230\n",
            "59/59 [==============================] - 16s 265ms/step - loss: 0.0879 - acc: 0.9678 - val_loss: 1.1905 - val_acc: 0.7815\n",
            "Epoch 24/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0891 - acc: 0.9705\n",
            "Epoch 24: val_acc did not improve from 0.78230\n",
            "59/59 [==============================] - 16s 267ms/step - loss: 0.0891 - acc: 0.9705 - val_loss: 1.2009 - val_acc: 0.7759\n",
            "Epoch 25/300\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0850 - acc: 0.9723\n",
            "Epoch 25: val_acc did not improve from 0.78230\n",
            "59/59 [==============================] - 16s 277ms/step - loss: 0.0850 - acc: 0.9723 - val_loss: 1.2226 - val_acc: 0.7791\n",
            "Epoch 25: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the tokenizer\n",
        "import pickle\n",
        "\n",
        "# Save tokenizer to a file\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "qIIgfpz-hw_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save(\"absa.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bfIo2bPqB3T",
        "outputId": "da4b0d8a-8b04-4c51-e89b-3506c330db69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Save the model in Protobuf format\n",
        "tf.saved_model.save(model, 'model_pb')\n"
      ],
      "metadata": {
        "id": "NeLvDyCJqQeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting our y_test label into OHE\n",
        "y_test= tf.keras.utils.to_categorical(y_test,num_classes=3)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "evaluation = model.evaluate([x_test_reviews_padded, x_test_aspects_padded], y_test)\n"
      ],
      "metadata": {
        "id": "6XKSo786qv0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae50b36c-4c66-415b-f8d6-6ade1c0bb9d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 4s 100ms/step - loss: 0.9891 - acc: 0.8061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the saved model\n",
        "model = tf.saved_model.load(\"pb_model\")"
      ],
      "metadata": {
        "id": "_249oUs6QN-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Inferencing"
      ],
      "metadata": {
        "id": "2xvPUG4psJ9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_review = None\n",
        "test_aspect = None\n",
        "label_map = {\n",
        "    0:'Negative',\n",
        "    1: 'Neutral',\n",
        "    2:'Positive'\n",
        "}\n",
        "\n",
        "# getting the test review\n",
        "while not test_review:\n",
        "    test_review = input(\"Enter your review: \")\n",
        "    if not test_review.strip():\n",
        "        print(\"Please enter a valid non-empty review.\")\n",
        "\n",
        "# preprocessing the test review\n",
        "cleaned_test_review=clean_text(test_review)\n",
        "cleaned_test_review=cleaned_test_review.lower()\n",
        "\n",
        "# getting the aspect\n",
        "while not test_aspect:\n",
        "    test_aspect = input(\"Enter the aspect: \")\n",
        "    if not test_aspect.strip():  # Check if the input is empty or only whitespace\n",
        "        print(\"Please enter a non-empty aspect.\")\n",
        "    elif len(test_aspect.split(\" \"))!=1:\n",
        "      print(\"Please enter a single aspect\")\n",
        "\n",
        "\n",
        "# preprocessing the test aspect\n",
        "cleaned_test_aspect=clean_text(test_review)\n",
        "cleaned_test_aspect=cleaned_test_aspect.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFozRYv4s5RI",
        "outputId": "079fde6c-3cdd-4730-d514-ead5255ff6fe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your review: This food tastes good\n",
            "Enter the aspect: Food\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the tokenzier\n",
        "with open('pb_model/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "# converting the test reviews to review sequences\n",
        "test_review_sequence=tokenizer.texts_to_sequences([cleaned_test_review])\n",
        "# padding the review sequences\n",
        "test_reviews_sequence_padded=tf.keras.preprocessing.sequence.pad_sequences(test_review_sequence,maxlen=20)\n",
        "\n",
        "# converting the test aspect to aspect sequence\n",
        "test_aspect_sequence=tokenizer.texts_to_sequences([cleaned_test_aspect])\n",
        "# padding the review sequences\n",
        "test_aspect_sequence_padded=tf.keras.preprocessing.sequence.pad_sequences(test_aspect_sequence,maxlen=2)"
      ],
      "metadata": {
        "id": "qPgTleiktzfs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model = tf.saved_model.load(\"pb_model\")\n",
        "\n",
        "# Convert input data to tensors\n",
        "test_review_tensor = tf.constant(test_reviews_sequence_padded, dtype=tf.float64)\n",
        "test_aspect_tensor = tf.constant(test_aspect_sequence_padded, dtype=tf.float64)\n",
        "\n",
        "# Perform inference using the appropriate signature\n",
        "infer = model.signatures[\"serving_default\"]\n",
        "output = infer(aspect_input_text=test_aspect_tensor, review_input_text=test_review_tensor)\n",
        "\n",
        "# Extract predictions from the output\n",
        "predictions = output[\"dense_56\"].numpy()\n",
        "\n",
        "# Get the predicted label using argmax\n",
        "predicted_label = label_map[np.argmax(predictions)]\n",
        "\n",
        "# Print the predicted label\n",
        "print(predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejMvjhGxSj9c",
        "outputId": "ad04a17f-d31c-48cb-8311-d7477414738f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # prediction\n",
        "# test_review_input= tf.keras.Input(shape=(20,),dtype=\"float64\")\n",
        "# test_aspect_input=tf.keras.Input(shape=(2,),dtype=\"float64\")\n",
        "\n",
        "# pred=model.predict([test_reviews_sequence_padded,test_aspect_sequence_padded])\n",
        "# print(label_map[np.argmax(pred)])"
      ],
      "metadata": {
        "id": "_C5yrszYse__"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kr4lTgPttlq-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
